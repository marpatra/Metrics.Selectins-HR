import numpy as np

# Sample dataset
data = [
    ("psoriasis", 143.8), ("psoriasis", 106.02), ("psoriasis", 140.8), ("psoriasis", 128.2), ("psoriasis", 108.8),
    ("psoriasis", 58.1), ("psoriasis", 104.6), ("psoriasis", 136.2), ("psoriasis", 54.42), ("psoriasis", 62.8),
    ("psoriasis", 101.94), ("psoriasis", 148), ("psoriasis", 116.4), ("psoriasis", 96.4), ("psoriasis", 105.44),
    ("psoriasis", 95.2), ("psoriasis", 45.4), ("psoriasis", 172), ("psoriasis", 64.76), ("psoriasis", 61.8),
    ("psoriasis", 40.4), ("psoriasis", 70.6), ("psoriasis", 73), ("psoriasis", 55.2), ("psoriasis", 11.2),
    ("psoriasis", 102.6), ("psoriasis", 32), ("psoriasis", 112.6), ("psoriasis", 67.2), ("psoriasis", 111.6),
    ("psoriasis", 123.4), ("psoriasis", 207.4), ("psoriasis", 228), ("psoriasis", 66.58), ("psoriasis", 106),
    ("psoriasis", 43.06), ("psoriasis", 99.96), ("psoriasis", 86.84), ("psoriasis", 62.82), ("psoriasis", 102.6),
    ("healthy", 72.2), ("healthy", 90.24), ("healthy", 78.4), ("healthy", 69.48), ("healthy", 48.64), ("healthy", 62.8),
    ("healthy", 61.32), ("healthy", 92.2), ("healthy", 110.34), ("healthy", 91.4), ("healthy", 91.2),
    ("healthy", 104.8),
    ("healthy", 68.3), ("healthy", 57.06), ("healthy", 82.5), ("healthy", 63.2), ("healthy", 65.94), ("healthy", 95.2),
    ("healthy", 77.14), ("healthy", 40.4), ("healthy", 100.4), ("healthy", 83.4), ("healthy", 94.2), ("healthy", 104.4),
    ("healthy", 76.08), ("healthy", 96.6), ("healthy", 71.06), ("healthy", 71.1), ("healthy", 112.64), ("healthy", 81),
    ("healthy", 91.96), ("healthy", 34.84), ("healthy", 56.8), ("healthy", 90), ("healthy", 112.06), ("healthy", 35.6),
    ("healthy", 45.82), ("healthy", 58.4), ("healthy", 77.2), ("healthy", 85.8)
]

X = np.array([x[1] for x in data]).reshape(-1, 1)
y = np.array([1 if x[0] == 'psoriasis' else 0 for x in data])


class LogisticRegression:
    b0 = 0
    b1 = 0
    sigmoid = np.array([])
    loss = np.array([])
    n = 0

    def fit(self, X, y):
        X_mean = np.mean(X)
        y_mean = np.mean(y)
        self.n = len(X)
        upward_function = 0
        downward_function = 0
        for i in range(self.n):
            upward_function += (X[i] - X_mean) * (y[i] - y_mean)
            downward_function += (X[i] - X_mean) ** 2
        self.b1 = upward_function / downward_function
        self.b0 = y_mean - (self.b1 * X_mean)
        return self.b0, self.b1

    def predict(self, Xi):
        z = self.b0 + (self.b1 * Xi)
        self.sigmoid = np.append(self.sigmoid, [1 / (1 + np.exp(-z))])
        return self.sigmoid

    def log_loss(self, y_true):
        log_loss = -np.mean(y_true * np.log(self.sigmoid) + (1 - y_true) * np.log(1 - self.sigmoid))
        return log_loss


model = LogisticRegression()
print(model.fit(X, y))
print(model.predict(X))
print("Log Loss:", model.log_loss(y))
