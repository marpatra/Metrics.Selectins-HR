import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import brier_score_loss

# 1. Create the dataset
diagnosis = (
    ["psoriasis"] * 36 +
    ["healthy"] * 40
)

p_selectin = [
    143.8, 106.02, 140.8, 128.2, 108.8, 58.1, 104.6, 136.2, 54.42, 62.8,
    101.94, 148, 116.4, 96.4, 105.44, 95.2, 45.4, 172, 64.76, 61.8, 40.4,
    70.6, 73, 55.2, 11.2, 102.6, 32, 112.6, 67.2, 111.6, 123.4, 207.4, 228,
    66.58, 106, 43.06, 99.96, 86.84, 62.82, 102.6, 72.2, 90.24, 78.4, 69.48,
    48.64, 62.8, 61.32, 92.2, 110.34, 91.4, 91.2, 104.8, 68.3, 57.06, 82.5,
    63.2, 65.94, 95.2, 77.14, 40.4, 100.4, 83.4, 94.2, 104.4, 76.08, 96.6,
    71.06, 71.1, 112.64, 81, 91.96, 34.84, 56.8, 90, 112.06, 35.6, 45.82,
    58.4, 77.2, 85.8
]

# 2. Ensure both lists have the same length
min_length = min(len(diagnosis), len(p_selectin))
diagnosis = diagnosis[:min_length]
p_selectin = p_selectin[:min_length]

# 3. Encode diagnosis as binary outcome: 1 = psoriasis, 0 = healthy
y = np.array([1 if d == "psoriasis" else 0 for d in diagnosis])

# 4. Predictor as 2D array for scikit-learn
X = np.array(p_selectin).reshape(-1, 1)

# 5. Fit logistic regression model: y ~ p_selectin
model = LogisticRegression(solver="lbfgs", max_iter=1000)
model.fit(X, y)

# 6. Predicted probabilities for the positive class (psoriasis)
predicted_prob = model.predict_proba(X)[:, 1]

# 7. Compute Brier Score
brier = brier_score_loss(y, predicted_prob)

print("Brier Score:", brier)
